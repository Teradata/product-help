<html><head></head><body><div class="nested0" aria-labelledby="ariaid-title1" topicindex="1" topicid="pwz1507564974181" id="pwz1507564974181"><h1 class="title topictitle1" id="ariaid-title1">POSTagger (ML Engine)</h1><div class="body conbody">
<p class="p">The POSTagger function creates part-of-speech (POS) tags for the words in the input text. POS tagging is the first step in the syntactic analysis of a language, and an important preprocessing step in many natural language-processing applications.</p>
<p class="p">The POSTagger function was developed on the Penn Treebank Project and Chinese Penn Treebank Project data set. Its POS tags comply with the tags defined by the two projects.</p>
<p class="p">For the parts of speech used, see the following:</p><div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="pwz1507564974181__table_vds_qfx_hdb" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:25%" span="1"></col><col style="width:75%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e42" rowspan="1" colspan="1">Text Language</th><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e44" rowspan="1" colspan="1">Parts of Speech</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e42" rowspan="1" colspan="1">English</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e44" rowspan="1" colspan="1"><a class="xref" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" target="_blank" title="" shape="rect">https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html</a></td></tr><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e42" rowspan="1" colspan="1">Chinese</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e44" rowspan="1" colspan="1"><a class="xref" href="https://www.sketchengine.co.uk/chinese-penn-treebank-part-of-speech-tagset/" target="_blank" title="" shape="rect">https://www.sketchengine.co.uk/chinese-penn-treebank-part-of-speech-tagset/</a></td></tr></tbody></table></div>
<p class="p">POSTagger uses files that are preinstalled on <span><b>ML Engine</b></span>. For details, see <a href="tzu1557778477026.md">Preinstalled Files That Functions Use</a>.</p></div><div class="topic reference nested1" aria-labelledby="ariaid-title2" topicindex="2" topicid="bfc1507565981326" xml:lang="en-us" lang="en-us" id="bfc1507565981326">
<h2 class="title topictitle2" id="ariaid-title2">POSTagger Syntax</h2><div class="body refbody"><div class="section" id="bfc1507565981326__section_N1000E_N1000C_N10001">
<h3 class="title sectiontitle">Version <span>2.7</span></h3><pre class="pre codeblock" xml:space="preserve"><code>SELECT * FROM POSTagger (
  <span>ON { <var class="keyword varname">table</var> | <var class="keyword varname">view</var> | (<var class="keyword varname">query</var>) }</span>
  USING
  TextColumn ('<var class="keyword varname">text_column</var>')]
  [ InputLanguage ({ 'en' | 'zh_Cn' }) ]
  <code class="ph codeph">[ Accumulate ({ '<var class="keyword varname">accumulate_column</var>' | <var class="keyword varname">accumulate_column_range</var> }[,...]) ]</code>
) AS <var class="keyword varname">alias</var>;</code></pre></div></div><div class="related-links"><div class="linklistheader"><p></p><b>Related Information</b></div>
<ul class="linklist linklist relinfo"><div class="linklistmember"><a href="ndv1557782188375.md">Column Specification Syntax Elements</a></div></ul></div></div><div class="topic reference nested1" aria-labelledby="ariaid-title3" topicindex="3" topicid="gan1507566214826" xml:lang="en-us" lang="en-us" id="gan1507566214826">
<h2 class="title topictitle2" id="ariaid-title3">POSTagger Syntax Elements</h2><div class="body refbody"><div class="section" id="gan1507566214826__section_N10011_N1000E_N10001"><dl class="dl parml"><dt class="dt pt dlterm">TextColumn</dt><dd class="dd pd">Specify the name of the input column that contains the text to tag.</dd><dt class="dt pt dlterm">InputLanguage</dt><dd class="dd pd">[Optional] Specify the language of the input text:
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="gan1507566214826__table_wh4_xbz_fdb" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:50%" span="1"></col><col style="width:50%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e182" rowspan="1" colspan="1">Option</th><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e184" rowspan="1" colspan="1">Description</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e182" rowspan="1" colspan="1"><code class="ph codeph">'en'</code> (Default)</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e184" rowspan="1" colspan="1">English</td></tr><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e182" rowspan="1" colspan="1"><code class="ph codeph">'zh_CN'</code></td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e184" rowspan="1" colspan="1">Simplified Chinese</td></tr></tbody></table></div></dd><dt class="dt pt dlterm">Accumulate</dt><dd class="dd pd">[Optional] Specify the names of the input table columns to copy to the output table.
<p class="p">If you intend to use the POSTagger output table as input to the function <a href="ibg1558536107902.md#sct1507564726632">TextChunker (ML Engine)</a>, then this syntax element must specify the input table columns that comprise the partition key.</p></dd></dl></div></div></div><div class="topic reference nested1" aria-labelledby="ariaid-title4" topicindex="4" topicid="pdi1507566310241" xml:lang="en-us" lang="en-us" id="pdi1507566310241">
<h2 class="title topictitle2" id="ariaid-title4">POSTagger Input</h2><div class="body refbody"><div class="section" id="pdi1507566310241__section_N1000E_N1000C_N10001"><div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="pdi1507566310241__table_uhb_prc_ycb" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:50%" span="1"></col><col style="width:50%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e236" rowspan="1" colspan="1">Table</th><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e238" rowspan="1" colspan="1">Description</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e236" rowspan="1" colspan="1">Input table</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e238" rowspan="1" colspan="1">Contains text to tag.</td></tr><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e236" rowspan="1" colspan="1">Model table</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e238" rowspan="1" colspan="1">Determined by InputLanguage syntax element:<div class="p"><div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="pdi1507566310241__table_cfw_2cz_fdb" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:50%" span="1"></col><col style="width:50%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e258" rowspan="1" colspan="1">InputLanguage</th><th class="entry cellrowborder" style="vertical-align:top;" id="d342693e260" rowspan="1" colspan="1">Model File</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e258" rowspan="1" colspan="1">English</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e260" rowspan="1" colspan="1"><span><i>pos_model_2.0_en_141008.bin</i></span></td></tr><tr class="row"><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e258" rowspan="1" colspan="1">Simplified Chinese</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e260" rowspan="1" colspan="1"><span><i>pos_model_2.0_zh_cn_141008.bin</i></span></td></tr></tbody></table></div></div>
<p class="p">These model files are preinstalled on <span><b>ML Engine</b></span>.</p></td></tr></tbody></table></div></div><div class="section" id="pdi1507566310241__section_on4_mrc_ycb">
<h3 class="title sectiontitle">Input Table Schema</h3>
<p class="p"><span>The table can have additional columns, but the function ignores them.</span></p><div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="pdi1507566310241__table_N10026_N1000E_N1000C_N10001" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:28.57142857142857%" span="1"></col><col style="width:14.285714285714285%" span="1"></col><col style="width:57.14285714285714%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry nocellnorowborder" style="vertical-align:top;" id="d342693e293" rowspan="1" colspan="1">Column</th><th class="entry nocellnorowborder" style="vertical-align:top;" id="d342693e295" rowspan="1" colspan="1">Data Type</th><th class="entry cell-norowborder" style="vertical-align:top;" id="d342693e297" rowspan="1" colspan="1">Description</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e293" rowspan="1" colspan="1"><var class="keyword varname">accumulate_column</var></td><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e295" rowspan="1" colspan="1">Any</td><td class="entry cell-norowborder" style="vertical-align:top;" headers="d342693e297" rowspan="1" colspan="1"><span>Column to copy to output table.</span></td></tr><tr class="row"><td class="entry row-nocellborder" style="vertical-align:top;" headers="d342693e293" rowspan="1" colspan="1"><var class="keyword varname">text_column</var></td><td class="entry row-nocellborder" style="vertical-align:top;" headers="d342693e295" rowspan="1" colspan="1">VARCHAR</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e297" rowspan="1" colspan="1">Text to tag. Each row of this column must contain a well-formatted sentence. To convert English text to formatted sentences, use <a href="ozn1558535803874.md#xrc1507558451771">SentenceExtractor (ML Engine)</a> function.</td></tr></tbody></table></div></div></div></div><div class="topic reference nested1" aria-labelledby="ariaid-title5" topicindex="5" topicid="pqx1507566419673" xml:lang="en-us" lang="en-us" id="pqx1507566419673">
<h2 class="title topictitle2" id="ariaid-title5">POSTagger Output</h2><div class="body refbody"><div class="section" id="pqx1507566419673__section_uj1_ysc_ycb">
<h3 class="title sectiontitle">Output Table Schema</h3><div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="pqx1507566419673__table_N1000E_N1000C_N10001" class="table" frame="border" border="1" rules="all"><div class="caption"></div><colgroup span="1"><col style="width:25%" span="1"></col><col style="width:12.5%" span="1"></col><col style="width:62.5%" span="1"></col></colgroup><thead class="thead" style="text-align:left;"><tr class="row"><th class="entry nocellnorowborder" style="vertical-align:top;" id="d342693e346" rowspan="1" colspan="1">Column</th><th class="entry nocellnorowborder" style="vertical-align:top;" id="d342693e348" rowspan="1" colspan="1">Data Type</th><th class="entry cell-norowborder" style="vertical-align:top;" id="d342693e350" rowspan="1" colspan="1">Description</th></tr></thead><tbody class="tbody"><tr class="row"><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e346" rowspan="1" colspan="1"><var class="keyword varname">accumulate_column</var></td><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e348" rowspan="1" colspan="1"><span>Same as in Input table</span></td><td class="entry cell-norowborder" style="vertical-align:top;" headers="d342693e350" rowspan="1" colspan="1">[Column appears once for each specified <var class="keyword varname">accumulate_column</var>.] <span>Column copied from input table.</span></td></tr><tr class="row"><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e346" rowspan="1" colspan="1">word_sn</td><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e348" rowspan="1" colspan="1">INTEGER</td><td class="entry cell-norowborder" style="vertical-align:top;" headers="d342693e350" rowspan="1" colspan="1">Word serial number (position of word in input text).</td></tr><tr class="row"><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e346" rowspan="1" colspan="1">word</td><td class="entry nocellnorowborder" style="vertical-align:top;" headers="d342693e348" rowspan="1" colspan="1">VARCHAR</td><td class="entry cell-norowborder" style="vertical-align:top;" headers="d342693e350" rowspan="1" colspan="1">Word extracted from input text.</td></tr><tr class="row"><td class="entry row-nocellborder" style="vertical-align:top;" headers="d342693e346" rowspan="1" colspan="1">pos_tag</td><td class="entry row-nocellborder" style="vertical-align:top;" headers="d342693e348" rowspan="1" colspan="1">VARCHAR</td><td class="entry cellrowborder" style="vertical-align:top;" headers="d342693e350" rowspan="1" colspan="1">POS tag of word.</td></tr></tbody></table></div></div></div></div><div class="topic reference nested1" aria-labelledby="ariaid-title6" topicindex="6" topicid="meq1510347451524" xml:lang="en-us" lang="en-us" id="meq1510347451524">
<h2 class="title topictitle2" id="ariaid-title6">POSTagger Example</h2><div class="body refbody"><div class="section" id="meq1510347451524__section_ipj_w2l_pdb">
<h3 class="title sectiontitle">Input</h3>
<ul class="ul" id="meq1510347451524__ul_epx_dz1_j2b">
<li class="li">Input table: Output table of <a href="ozn1558535803874.md#rmi1510347767254">SentenceExtractor Example</a></li></ul></div><div class="section" id="meq1510347451524__section_ns5_w2l_pdb">
<h3 class="title sectiontitle">SQL Call</h3><pre class="pre codeblock" xml:space="preserve"><code>SELECT * FROM POSTagger (
  ON SentenceExtractor (
    ON paragraphs_input 
    USING
    TextColumn ('paratext')
    Accumulate ('paraid')
  ) 
  USING
  TextColumn ('sentence')
  Accumulate ('sentence','sentence_sn')
) AS dt ORDER BY sentence_sn, word_sn;</code></pre></div><div class="section" id="meq1510347451524__section_oq2_x2l_pdb">
<h3 class="title sectiontitle">Output</h3><pre class="pre screen" xml:space="preserve"> sentence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      sentence_sn word_sn word                pos_tag 
 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ----------- ------- ------------------- ------- 
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       1 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       1 logistic            JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       1 association         NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       1 decision            NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       1 cluster             NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       2 analysis            NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       2 regression          NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       2 tree                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       2 rule                NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       2 statistics          NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       3 was                 VBD    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       3 learning            NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       3 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       3 learning            NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       3 or                  CC     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       4 clustering          NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       4 is                  VBZ    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       4 developed           VBN    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       4 simple              JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       4 uses                VBZ    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       5 a                   DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       5 linear              JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       5 is                  VBZ    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       5 by                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       5 a                   DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       6 decision            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       6 method              NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       6 regression          NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       6 the                 DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       6 statistician        JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       7 david               JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       7 task                NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       7 tree                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       7 for                 IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       7 is                  VBZ    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       8 the                 DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       8 cox                 NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       8 discovering         VBG    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       8 as                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       8 of                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1       9 a                   DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1       9 in                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1       9 grouping            VBG    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1       9 least               JJS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1       9 interesting         JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      10 a                   DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      10 squares             VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      10 relations           NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      10 1958[2][3](although JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      10 predictive          JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      11 between             IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      11 model               NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      11 much                JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      11 set                 NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      11 estimator           NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      12 of                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      12 of                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      12 variables           NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      12 which               WDT    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      12 work                NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      13 maps                VBZ    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      13 objects             NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      13 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      13 was                 VBD    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      13 a                   DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      14 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      14 done                VBN    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      14 observations        NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      14 large               JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      14 linear              JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      15 regression          NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      15 such                PDT    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      15 about               IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      15 in                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      15 databases           NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      16 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      16 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      16 a                   DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      16 model               NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      16 an                  DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      17 way                 NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      17 with                IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      17 item                NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      17 single              JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      17 it                  PRP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      18 that                WDT    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      18 to                  TO     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      18 independent         JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      18 is                  VBZ    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      18 a                   DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      19 variable            JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      19 single              JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      19 objects             VBZ    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      19 conclusions         NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      19 intended            VBN    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      20 case                NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      20 explanatory         NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      20 to                  TO     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      20 in                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      20 about               IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      21 almost              RB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      21 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      21 identify            VB     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      21 variable            JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      21 the                 DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      22 .                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      22 strong              JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      22 items               NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      22 same                JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      22 two                 CD     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      23 rules               NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      23 in                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      23 group               NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      23 target              NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      23 decades             NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      24 (                   O      
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      24 other               JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      24 value               NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      24 discovered          VBN    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      24 earlier)            VBP    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      25 words               NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      25 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      25 called              VBD    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      25 .                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      25 in                  IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      26 ,                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      26 a                   DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      26 databases           NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      26 it                  PRP    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      26 the                 DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      27 cluster             NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      27 is                  VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      27 using               VBG    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      27 simple              JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      27 binary              JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      28 linear              JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      28 )                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      28 different           JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      28 logistic            JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      28 one                 CD     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      29 regression          NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      29 are                 VBP    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      29 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      29 model               NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      29 measures            NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      30 more                RBR    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      30 the                 DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      30 fits                VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      30 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      30 is                  VBZ    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      31 similar             JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      31 predictive          JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      31 interestingness     NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      31 a                   DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      31 used                VBN    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      32 straight            JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      32 modelling           JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      32 .                   O      
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      32 to                  TO     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      32 (                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      33 approaches          NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      33 line                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      33 based               VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      33 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      33 estimate            VB     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      34 through             IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      34 used                VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      34 some                DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      34 on                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      34 the                 DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      35 the                 DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      35 in                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      35 the                 DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      35 sense               NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      35 probability         NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      36 set                 NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      36 concept             NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      36 statistics          NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      36 or                  CC     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      36 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      37 a                   DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      37 of                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      37 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      37 of                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      37 another             DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      38 n                   JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      38 strong              JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      38 )                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      38 data                NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      38 binary              JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      39 points              NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      39 mining              NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      39 response            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      39 rules               NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      39 to                  TO     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      40 and                 CC     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      40 ,                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      40 each                DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      40 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      40 based               VBN    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      41 such                PDT    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      41 machine             NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      41 rakesh              JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      41 other               JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      41 on                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      42 one                 CD     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      42 a                   DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      42 learning            VBG    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      42 agrawal             JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      42 than                IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      43 way                 NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      43 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      43 to                  TO     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      43 et                  NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      43 or                  CC     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      44 those               DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      44 that                WDT    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      44 tree                CD     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      44 al.[2               NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      44 more                JJR    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      45 models              NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      45 makes               VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      45 ]                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      45 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      45 predictor           NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      46 (                   O      
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      46 the                 DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      46 other               JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      46 introduced          JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      46 where               WRB    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      47 sum                 NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      47 association         NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      47 groups              NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      47 the                 DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      47 or                  CC     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      48 (                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      48 rules               NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      48 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      48 independent         JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      48 target              NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      49 squared             JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      49 clusters)           NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      49 variable            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      49 for                 IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      49 )                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      50 discovering         VBG    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      50 residuals           NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      50 .                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      50 can                 MD     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      50 variables           VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      51 regularities        NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      51 of                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      51 it                  PRP    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      51 take                VB     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      51 (                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      52 between             IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      52 the                 DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      52 is                  VBZ    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      52 a                   DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      52 features)           NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      53 model               NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      53 a                   DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      53 products            NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      53 finite              JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      53 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      54 main                JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      54 (                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      54 in                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      54 set                 NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      54 as                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      55 task                NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      55 that                WDT    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      55 large-scale         JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      55 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      55 such                JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      56 is                  VBZ    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      56 of                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      56 values              NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      56 transaction         NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      56 it                  PRP    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      57 is                  VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      57 data                NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      57 exploratory         JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      57 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      57 are                 VBP    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      58 not                 RB     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      58 vertical            JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      58 data                NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      58 called              VBN    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      58 recorded            VBN    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      59 a                   DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      59 mining              NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      59 distances           NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      59 by                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      59 classification      NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      60 trees               NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      60 between             IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      60 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      60 point-of-sale       NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      60 classification      NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      61 and                 CC     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      61 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      61 (                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      61 .                   O      
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      61 method              NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      62 a                   DT     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      62 points              NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      62 pos                 NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      62 in                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      62 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      63 common              JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      63 of                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      63 )                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      63 these               DT     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      63 it                  PRP    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      64 the                 DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      64 tree                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      64 systems             NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      64 could               MD     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      64 technique           NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      65 data                NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      65 in                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      65 structures          NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      65 be                  VB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      65 for                 IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      66 set                 VBN    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      66 supermarkets        NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      66 ,                   O      
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      66 called              VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      66 statistical         JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      67 and                 CC     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      67 .                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      67 leaves              VBZ    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      67 a                   DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      67 data                NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      68 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      68 for                 IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      68 represent           JJ     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      68 qualitative         JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      68 analysis            NN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      69 fitted              JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      69 example             NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      69 class               NN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      69 response/discrete   JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      69 ,                   O      
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      70 line                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      70 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      70 labels              NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      70 choice              NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      70 used                VBN    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      71 )                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      71 the                 DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      71 and                 CC     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      71 model               NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      71 in                  IN     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      72 as                  RB     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      72 rule                NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      72 branches            NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      72 in                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      72 many                JJ     
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      73 small               JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      73 {                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      73 represent           VBP    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      73 the                 DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      73 fields              NNS    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      74 as                  IN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      74 onions              NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      74 conjunctions        NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      74 terminology         NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      74 ,                   O      
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      75 possible            JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      75 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      75 of                  IN     
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      75 of                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      75 including           VBG    
 in statistics, simple linear regression is the least squares estimator of a linear regression model with a single explanatory variable. in other words, simple linear regression fits a straight line through the set of n points in such a way that makes the sum of squared residuals of the model (that is, vertical distances between the points of the data set and the fitted line) as small as possible.                                                                                                                                                                                                                                                                                                                         1      76 .                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      76 potatoes}=>{burger  NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      76 features            NNS    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      76 economics           NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      76 machine             NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      77 }                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      77 that                WDT    
 logistic regression was developed by statistician david cox in 1958[2][3](although much work was done in the single independent variable case almost two decades earlier). the binary logistic model is used to estimate the probability of a binary response based on one or more predictor (or independent) variables (features). as such it is not a classification method. it could be called a qualitative response/discrete choice model in the terminology of economics.                                                                                                                                                                                                                                                         1      77 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      77 learning            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      78 found               VBN    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      78 lead                VBP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      78 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      79 in                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      79 to                  TO     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      79 pattern             JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      80 the                 DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      80 those               DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      80 recognition         NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      81 sales               NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      81 class               NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      81 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      82 data                NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      82 labels              NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      82 image               NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      83 of                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      83 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      83 analysis            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      84 a                   DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      84 decision            NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      84 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      85 supermarket         NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      85 trees               NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      85 information         NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      86 would               MD     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      86 where               WRB    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      86 retrieval           NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      87 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      87 indicate            VB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      87 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      88 target              NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      88 that                IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      88 and                 CC     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      89 bioinformatics      NNS    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      89 if                  IN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      89 variable            NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      90 .                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      90 a                   DT     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      90 can                 MD     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      91 customer            NN     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      91 take                VB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      91 cluster             NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      92 buys                VBZ    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      92 continuous          JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      92 analysis            NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      93 onions              NNS    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      93 values              NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      93 itself              PRP    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      94 and                 CC     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      94 (                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      94 is                  VBZ    
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      95 potatoes            VBZ    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      95 typically           RB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      95 not                 RB     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      96 together            RB     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      96 real                JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      96 one                 CD     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      97 ,                   O      
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      97 numbers             NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      97 specific            JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      98 they                PRP    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      98 )                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      98 algorithm           NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1      99 are                 VBP    
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1      99 are                 VBP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1      99 ,                   O      
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     100 likely              JJ     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1     100 called              VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     100 but                 CC     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     101 to                  TO     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1     101 regression          NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     101 the                 DT     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     102 also                RB     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1     102 trees               NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     102 general             JJ     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     103 buy                 VB     
 decision tree learning uses a decision tree as a predictive model which maps observations about an item to conclusions about the items target value. it is one of the predictive modelling approaches used in statistics, data mining and machine learning. tree models where the target variable can take a finite set of values are called classification trees. in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.                                                                                                   1     103 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     103 task                NN     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     104 hamburger           JJR    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     104 to                  TO     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     105 meat                NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     105 be                  VB     
 association rule learning is a method for discovering interesting relations between variables in large databases. it is intended to identify strong rules discovered in databases using different measures of interestingness. based on the concept of strong rules, rakesh agrawal et al.[2] introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (pos) systems in supermarkets. for example, the rule {onions, potatoes}=>{burger} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.                                                          1     106 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     106 solved              VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     107 .                   O      
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     108 it                  PRP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     109 can                 MD     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     110 be                  VB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     111 achieved            VBN    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     112 by                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     113 various             JJ     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     114 algorithms          NNS    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     115 that                WDT    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     116 differ              VBP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     117 significantly       RB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     118 in                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     119 their               PRP$   
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     120 notion              NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     121 of                  IN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     122 what                WP     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     123 constitutes         VBZ    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     124 a                   DT     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     125 cluster             NN     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     126 and                 CC     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     127 how                 WRB    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     128 to                  TO     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     129 efficiently         RB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     130 find                VB     
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     131 them                PRP    
 cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense or another) to each other than to those in other groups (clusters). it is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, and bioinformatics. cluster analysis itself is not one specific algorithm, but the general task to be solved. it can be achieved by various algorithms that differ significantly in their notion of what constitutes a cluster and how to efficiently find them.           1     132 .                   O</pre>
<p class="p">Download a zip file of all examples and a SQL script file that creates their input tables from the attachment in the left sidebar.</p></div></div></div></div></body></html>
