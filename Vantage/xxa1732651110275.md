Also referred to as data drift, feature drift is based on understanding and monitoring changes in the dataset statistics the model was trained on versus the dataset statistics the model is currently predicting. You can monitor this data in an offline process or in real time, as data is fed into the model, to analyze and capture dataset statistics when it has evolved past a certain â€œdivergenceâ€? threshold or if it has changed completely. Dataset statistics include only distribution histogram and frequencies to focus column data and importance.

**Variables: Features and Targets**

*Features* are the basic building blocks of datasets. The quality of the features in your dataset affects the quality of the insights you will gain when you use that dataset for training and evaluating models.

The Importance property in feature drift is measured by calculating the increase in the model's prediction error after permuting the feature.

-   A feature is important if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction.


-   A feature is unimportant if shuffling its values leaves the model error unchanged, because in this case the model ignored the feature for the prediction.


Predictions (or *targets*) are the variables used to train the model or evaluate the accuracy and precision, in combination with the rest of the dataset features. For training and evaluation purposes, the features and targets data must be historical and curated.

