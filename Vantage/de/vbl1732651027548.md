Verwenden Sie den Bewertungsbericht, um ein Modell zu bewerten und ein Modell basierend auf seiner Leistung als bestes Modell zu kennzeichnen. Sie können den Bewertungsbericht einsehen, der die Modellleistung in Form bestimmter Metriken hervorhebt, und Modelle anhand der Metrikwerte vergleichen.

Der Bericht zur Modellbewertung zeigt die folgenden Bereiche:

-   Details zur Modellversion

-   Schlüsselmetriken

-   Metriken

-   Leistungsdiagramme

-   Aktionen

**Details zur Modellversion** listet alle Details der Modellversion, des Trainings und der Bewertungsaufträge auf. Die folgenden Details werden in Bezug auf den Trainingsauftrag angezeigt:

-   **Modellversions-ID**

    Gibt die Modellversions-ID an. Sie können den Link zur Modellversions-ID auswählen, um zur Seite **Lebenszyklus der Modellversion** zu gelangen.

-   **Auftrags-ID der Bewertung**

    Gibt die Auftrags-ID der Bewertung an. Sie können auf den Link „Auftrags-ID“ klicken, um zu den Details des Auftrags zu gelangen.

-   **Datum der Bewertung**

    Gibt das Datum der Bewertung an.

-   **Dataset-ID**

    Zeigt die Trainings-Dataset-ID an, der zum Trainieren des Auftrags verwendet wurde. Wählen Sie den **Dataset-ID**-Link aus, um die Dataset-Details anzuzeigen.

-   **Dataset-Name**

    Zeigt den Namen des Trainings-Datasets an, der zum Trainieren des Auftrags verwendet wird.

-   **Hyperparameter**

    Gibt die für die Ausführung des Auftrags definierten Hyperparameter einschließlich eta und max\_depth an.

**Schlüsselmetriken** zeigt die Schlüsselmetriken an, die Sie im Bereich „Metriken“ markieren. Dies kann eine Liste von Leistungsmetriken umfassen. Sie können einige der Metriken als **Schlüsselmetriken** markieren, um sie leicht zugänglich zu machen. In diesem Bereich werden alle wichtigen Metriken angezeigt.

**Metriken** listet die Leistungsmetriken und ihre Werte für die aktuelle Modellversion auf, die eine Liste von Metriken enthalten kann, darunter Genauigkeit, Rückruf, Präzision und F1-Score. Verwenden Sie die Option **Als Schlüsselmetrik festlegen**, um die wichtigsten Metriken für die Anzeige im Bereich **Schlüsselmetriken** zu markieren. Eine Liste gängiger Leistungsmetriken ist:

-   **Genauigkeit**

    Das Verhältnis der Anzahl der richtigen Prognosen zur Gesamtzahl der Eingabebeispiele.

-   **Rückruf**

    Die Anzahl der richtig-positiven Ergebnisse geteilt durch die Anzahl aller relevanten Beispiele (alle Beispiele, die als positiv hätten identifiziert werden müssen).

-   **Präzision**

    Die Anzahl der richtig-positiven Ergebnisse geteilt durch die Anzahl der von der Klassifizierung vorhergesagten positiven Ergebnisse.

-   **F1-Score**

    Das harmonische Mittel zwischen Präzision und Rückruf. Der Bereich für F1-Score ist (0,1). Er zeigt Ihnen, wie präzise Ihre Klassifizierung ist (wie viele Instanzen sie richtig klassifiziert) und wie robust sie ist (sie übersieht keine signifikante Anzahl von Instanzen).

**Leistungsdiagramme** zeigt eine Reihe von Leistungsdiagrammen an, die auf verschiedenen Metriken basieren, darunter die Konfusionsmatrix, die ROC-Kurve und die Wichtigkeit der SHAP-Merkmale. Verwenden Sie diese Tabellen, um die Leistung des Modells visuell zu überwachen und zu entscheiden, ob Sie das Modell als bestes Modell kennzeichnen möchten.

-   **Konfusionsmatrix**

    Eine N x N-Matrix, die die Modellleistung bewertet, wobei N die Anzahl der Zielklassen ist. Die Matrix vergleicht die tatsächlichen Zielwerte mit denen, die vom maschinellen Lernmodell vorhergesagt wurden.

-   **ROC-Kurve**

    Dieses Diagramm fasst den Kompromiss zwischen der Rate der echten positiven Ergebnisse und der Rate der falschen positiven Ergebnisse für ein Prognosemodell mit unterschiedlichen Wahrscheinlichkeitsschwellenwerten zusammen.

-   **Bedeutung des SHAP-Merkmals**

    Dieses Diagramm basiert auf der Größenordnung der Merkmalszuweisungen.

**Aktionen** verwenden den Modellbewertungsbericht, um eine der folgenden Aktionen an der aktuellen Modellversion durchzuführen.

-   **Genehmigen**: Genehmigt die Modellversion.

-   **Ablehnen**: Genehmigt die Modellversion.

-   **Als bestes Modell markieren/entfernen** markiert/entfernt die Modellversion als beste Version basierend auf ihrer Leistung.

-   **Modellabweichung anzeigen** öffnet die Seite „Modellabweichung“, auf der Sie die Modellleistung überwachen können.
