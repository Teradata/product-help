Use the Alerts option to monitor the performance of models and model versions against specific key metrics. In addition to metric gathering and tracking, model monitoring involves alerting based on these metric values. The purpose of alerting is to detect important deviations in the data used to train a model versus the data currently being used in scoring. Use this detection to set alert thresholds on key metrics related to the deviation of data. You can define alerts for a selected model version by setting thresholds on performance metrics and view the details of all active alerts.

From the environment, select **AI workbench** > **ModelOps** > **Projects** > the project > **Alerts** in the Navigation bar.

